\documentclass[11pt]{article}  %11 or 12 pt

\usepackage{graphics,graphicx}
\usepackage{color, colortbl}
\usepackage{multicol} 
\usepackage{parskip}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage[utf8]{inputenc}
\usepackage{fancyhdr}
\usepackage[title]{appendix}
\usepackage{wasysym}
\usepackage{url}
\usepackage{subcaption}

\usepackage[font=footnotesize,labelfont=small]{caption}
\captionsetup{width=0.85\linewidth}
\definecolor{LightCyan}{rgb}{0.7,1,1}

\RequirePackage{geometry}
\geometry{margin=1in}

\renewcommand{\rmdefault}{phv} % Arial
\renewcommand{\sfdefault}{phv} % Arial

\usepackage{sectsty} % can change font, size of the section headings.  
\sectionfont      {\fontsize{12pt}{3}\usefont{OT1}{phv}{b}{sc}\selectfont}
\subsectionfont   {\fontsize{11pt}{3}\usefont{OT1}{phv}{b}{n}\selectfont}
\subsubsectionfont{\fontsize{11pt}{3}\usefont{OT1}{phv}{m}{n}\selectfont}

\renewcommand{\thesection}{\Alph{section}} % so that section headings use A B C instead 1 2 3
\renewcommand{\baselinestretch}{1}

\newcommand{\inden}[1]{\mbox{} \hspace{#1} } % Force horizontal spaces.  

\setlength{\parskip}{0.2cm}
\setlength{\parindent}{0pt}
\renewcommand{\baselinestretch}{1.15}

\title{Spiking Neural Network on \\ Gender Classification from Speech Data}
\author{
	Tai Duc Nguyen \\
	Dept. Electrical and Computer Engineering \\
	Drexel University \\
	Philadelphia, PA, USA \\
	tdn47@drexel.edu
}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
	Spiking Neural Network, or SNN, provides a good trade-off between power consumption and accuracy, in comparison to a Convolutional Neural Network (CNN) of the same size. In a SNN, only a portion of the connected neurons remain active to fire spikes in a particular fashion, when the network is presented with a simulus at the input layer. This behavior allows the network to not only be very energy efficient, but also be capable of employing biologically plausible plasticity rules. In this paper, an unsupervised Spiking Neural Network model is simulated using C++ and applied to classify gender information in speech data. Our model is able to achieve an accuracy of 96.5\%, while consuming 55 times less power and running at 3 times the speed, in comparison to a CNN of the same size.
\end{abstract}

\section{Introduction}
\label{intro}

It is no myths that Convolutional Neural Networks are computationally intensive \cite{b1}. Hence, no meaningful machine learning applications using CNNs can be run on small electronic devices in a reasonable amount of time. Often, data from customers' sensors are collected and sent to a very powerful super-computer for processing using CNNs. However, this is not how human brains work -- we do not amass gigabytes of information from every sensor in our body every millisecond and send it somewhere for processing. We would drive into each other before we can react to the things in front of our eyes. Therefore, in order to advance the state of art in the field of human-machine integration, it is necessary to innovate ways to introduce machine learning capabilities with good classification accuracy and security into ultra-low energy devices. If this is achievable, it is possible for human and machine to integrate using Brain-Machine Interfaces (BMI), currently developed by researchers at Neuralink \cite{b2}. In this paper, Spiking Neural Networks will be shown that they can be the solution to the predicament of information processing in machine-human integration. 

\section{Background on Spiking Neural Network}
\label{bg_snn}

\subsection{Spiking Neural Network}

Spiking Neural Networks are fundamentally different from any second generation's neural nets. Their neuronal models operate closely to those inside the human brain. In short, two neurons, the pre-synaptic neuron and the post-synaptic neuron, are connected by a synapse with a certain \textit{weight number}. As the pre-synaptic neuron fires spikes towards the post-synaptic neuron, electrical charges accumulate at the latter until its potential threshold is breached. Once breached, the neuron sends spikes towards the next neuron it is connected to, and its membrane potential is reset \cite{b3}. Using this neuronal behavior, the network "learns" using Spike-Timing Dependent Plasticity (STDP), which is a principle that partially explains the biological process of synapses' strength adjustments. STDP states that \cite{b4}:

\begin{itemize}
	\item Long-term potentiation (LTP) occurs when the pre-synaptic neuron spikes immediately \textit{before} the post-synaptic neuron spikes.
	\item Long-term depression (LTD) occures when the pre-synaptic neuron spikes immediately \textit{after} the post-synaptic neuron spikes.
\end{itemize}

Hence, in our SNN neuron model, the \textit{weight number}, which determines the likelihood of the pre-synaptic neuron to spike the next time around, increases with LTP and decreases with LTD. In a network trained with STDP, a certain group of neurons will fire in a certain pattern when a particular stimulus is introduced at the input layer. 

\subsection{Leaky Integrate-and-Fire Neurons}

There are 3 common neuronal models (listed with increasing complexity): Leaky Integrate-and-Fire (LIF), Izhikevic 4-parameters, and Izhikevic 9-parameters. This paper will focus only on the LIF model, whose neurons' behavior is governed by the following equation \cite{b5}:

\begin{equation}
	C\frac{dV}{dt} = -g_L(V(t) - V_R) + I(t)
	\label{eq1}
\end{equation}

A LIF neuron is a parallel combination of a "leaky" resistor with conductance $g_L$ and a capacitor with capacitance $C$. When $V(t)$ reaches a threshold level $V_{th}$, the capacitor discharges to a resting potential $V_R$. Since the biological neuron also "undershoots" $V_R$ at the discharging phase (so called Afterhyperpolarization - AHP), there exists a relative refractory period where the neuron cannot fire any new spikes if it is activated by smaller or equal potential. This behavior can be modeled with a dynamic potential threshold $V_{th}$: following each spike, increase $V_{th}$ by an amount \cite{b6}:

\begin{equation}
	V_{th\_next} = V_{th\_prev}(1+\tau t)
	\label{eq2}
\end{equation}

where $t$ is the amount of time passed from last spike. 

\subsection{Poisson Spike Model}

One problem with the LIF neuron model described above is that it is too deterministic in comparison to a neurons in the cortex. The spikes generated by our brains' neurons are highly randomized, which insinuates two possible theories:

\begin{itemize}
	\item Theory 1: The irregular interspike interval (ISI) represents a random process, where the exact moments of the spikes do not hold meaningful information, but rather facilitate noise introduction into the system.
	\item Theory 2: The spike timing holds relevant information about a pre-synaptic event. Hence the ISI in conjunction with firing rate can represents a very large amount of information.
\end{itemize}

From these two theories, there are two main information encoding techniques: rate encoding and time encoding. Rate encoding is done by translating information into the number of spikes per unit time; and time encoding is accomplished by converting information into ISI. The SNN described in this paper leverages rate encoding together with a Poisson Spike model so as to preserve the property of "randomness".

The equation describing Poisson distribution is known as:

\begin{equation}
	f(k; \lambda) = \frac{\lambda^k e^{-k}}{k!}
	\label{eq3}
\end{equation}

Hence, if the spike rate $r$ is defined as the number of spikes $s$ over an interval $T$, $r = s/T$, then the probability that $n$ spikes ($n < s$) happen in a sub-interval $\Delta t$ is:
	
\begin{equation}
	P(n \in \Delta t) = C^n_s(\Delta t/T)^n(1- \Delta t/T)^{s-n}
	\label{eq4}
\end{equation}

if $k \rightarrow \infty$, $T \rightarrow \infty$ and $r$ stays constant:

\begin{equation}
	P(n \in \Delta t) = \frac{(r\Delta t)^n e^{-r\Delta t}}{n!}
	\label{eq5}
\end{equation}

When $\Delta t$ is small and $r\Delta t << 1$, $P(n=1 \in \Delta t)$ can be approximated with $r\Delta t$. Hence, for each interval $i$, a number between 0 and 1 is generated from the Uniform distribution, $x[i]$, such that: if $x[i] \le r\Delta t$, then a spike is initiated. The SNN described here uses this method to encode audio information into spike trains.

\section{Background on CARLsim4}
\label{bg_carlsim4}

As a collaborative effort between Drexel University and University of California, Irvine to advance in the domain of Spiking Neural Networks, the SNN simulator chosen for this paper is CARLsim4. 

CARLsim4 is a GPU-accelerated SNN simulation tool written in C++ by researchers at the Cognitive Anteater Robotics Laboratory in University of California, Irvine. This software provides the basic underlying framework to create an application using a Spiking Neural Network. Its discovered and understood capabilities \footnote{Other capabilities are available in the software but will not be focused.} include:

\begin{itemize}
	\item Definitions of the Izhikevich 4-Parameters, Izhikevich 9-Parameters and LIF neuronal model
	\item Mechanisms to support building connections between groups of neurons of the same/different model
	\item Mechanisms to support simulating information encoding and spike train generation 
	\item Mechanisms to support STDP and Homeostatis
	\item Two monitoring mechanisms for developing and post-processing
	\item GPU accelerated for very large networks
\end{itemize}

CARLsim4's workflow composes of 3 states (shown in figure below): Config, Setup, and Run. The Config state is where the topologies of the network, or, groups of neurons along with their connections to one another are defined. The Setup state allows the user to choose the back-end (CPU or GPU) of the network, and bring up monitors to look at a particular neuron/layer. The Run state is responsible for spike train generation and the executions of all neurons in the network. The state/output of the network can also be stored for post-processing or demoing at the end of the Run state.

% Include figure on carlsim4 workflow

In addition, two monitoring tools, available in CALRsim4, can write outputs to binary files, which can be used in the software's MATLAB Offline Analysis Toolbox (OAT). The outputs of the SNN in this paper will be piped into MATLAB for K-Means clustering.

\section{Background on DARPA's TIMIT Acoustic-Phonetic Continuous Speech Dataset}
\label{dataset}

This dataset (will be refered later on as TIMIT) is created as a joint effort between: Massachusetts Institute of Technology (MIT), Stanford Research Institute (SRI), and Texas Instruments (TI), under the funding of the Defense Advanced Research Projects Agency - Information Science and Technology Office (DARPA-ISTO) \cite{b7}. 

TIMIT contains the transcripts and CD quality audio data of 6300 sentences, in which the same 10 sentences is recorded by each of the 630 speakers from 8 major dialects in the United States of America. The dialects' regions are as follows:

\begin{itemize}
	\item DR1: New England
	\item DR2: Northern
	\item DR3: North Midland
	\item DR4: South Midland
	\item DR5: Southern
	\item DR6: New York City
	\item DR7: Western
	\item DR8: Army Brat (moved around)
\end{itemize}

The gender distribution for each region is listed in Table \ref{table1} below:

\begin{table}[htbp]
	\begin{center}
		\begin{tabular}{|c|c|c|c|}
			\hline
			\textbf{Dialect Region (DR)}&\textbf{\# Male}&\textbf{\# Female}&\textbf{Total} \\
			\hline
			1 & 31 (63\%) & 18 (27\%) & 49 (8\%) \\
			\hline
			2 & 71 (70\%) & 31 (30\%) & 102 (16\%) \\
			\hline
			3 & 79 (67\%) & 23 (23\%) & 102 (16\%) \\
			\hline
			4 & 69 (69\%) & 31 (31\%) & 100 (16\%) \\
			\hline
			5 & 62 (63\%) & 36 (37\%) & 98 (16\%) \\
			\hline
			6 & 30 (65\%) & 16 (35\%) & 46 (7\%) \\
			\hline
			7 & 74 (74\%) & 26 (26\%) & 100 (16\%) \\
			\hline
			8 & 22 (67\%) & 11 (33\%) & 33 (5\%) \\
			\hline
			\rowcolor{LightCyan}
			ALL & 438 (70\%) & 192 (30\%) & 630 (100\%) \\
			\hline
		\end{tabular}
		\caption{Table detailing the gender distribution for each dialect region in TIMIT}
		\label{table1}
	\end{center}
\end{table}

From the table above, it is clear that TIMIT is skewed because the male population is 2.3 times the female population. Hence, for the purpose of balancing, speech data from 192 randomly selected males (out of 438) will be chosen to form the database along with those from 192 females. Therefore, the total amount of audio clips to be processed is 3840.

\section{Experimental Setup}
\label{experimental_setup}

\subsection{Data Pre-processing Using MFCCs}

The audio data available is in the "wav" file format -- a list of millions of 32-bit floating point numbers. There are no correlations between these numbers and the speaker's gender. Hence, it is necessary to transform the data into a different, more concise and more meaningful representation. The most famous transformation is the Short-Term-Fourier-Transform (STFT), which produces a spectrogram -- a 2D matrix that entails the energy at a certain frequency band in a particular time period. 

Due to the fact that the dataset is composed of people with diverse dialects speaking distinct sentences, the STFT spectrogram will look tremendously different from person to person and from sentences to sentences. Therefore, in order to further concise the STFT spectrogram to eliminate these differences, a spectrogram-of-a-spectrogram, or, a cepstral is constructed for each audio signal. In addition, the filter banks (frequency bands) used in the first spectrogram is derived from the nonlinear Mel scale \cite{b8} so that the resulting spectra reflect human hearing better. This combination is called the Mel-frequency cepstrum (MFC). And the coefficients of all MFCs are called the Mel-frequency cepstral coefficients (MFCC).

In addition to performing MFCC analysis on each audio signal, silent and noise removal is also performed 


Hence, for each audio signal, the MFCC is created

\subsection{SNN Architecture}
The SNN in this paper consists of 3 different layers: one input layer, one hidden layer and one max-pooling layer. 




\section{Simulation Results}
\label{sim_res}







\section{Future Works}
\label{future_works}


\begin{thebibliography}{00}
	\bibitem{b1} 
	\bibitem{b2} 
	\bibitem{b3} 
	\bibitem{b4} 
	\bibitem{b5} 
	\bibitem{b6} D C Somers, S B Nelson, and M Sur.  An emergent model of orientation selectivity in cat visualcortical simple cells. Journal of Neuroscience, 15:5448â€“5465, 1995.
	\bibitem{b7}
	\bibitem{b8}
	\bibitem{b9}
	\bibitem{b10}
\end{thebibliography}

\end{document}
